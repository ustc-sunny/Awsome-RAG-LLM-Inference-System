# Awsome-LLM-Inference-in-limited-resource
A survey about LLM inference on limited resource, like single GPU, mobile device, etc.
